{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Keras это высокоуровневая обертка над tensorflow. Но в текущих реализациях библиотеке tf они живут очень рядом. \n",
    "Когда мы собираем свои нейронки мы берем уже готовые слои из keras и добавляем что-то свое, если нам требуется.\n",
    "Но keras можно использовать без явного использования TF пытаясь свести задачу к fit-predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "Самое простое, что мы можем сделать это собирать слои последовательно друг за другом - займемся же этим!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers as L # подгружаем нужные модули. \n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в keras лежит несколько наборов данных. Для примера возьмем fashion_mnist - как mnist, но про предметы одежды :)\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10**4, random_state=42)\n",
    "\n",
    "X_train = X_train/ 255.\n",
    "X_val = X_val/ 255.\n",
    "X_test = X_test/ 255.\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-shirt/top'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2])\n",
    "class_names[y_train[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1254902 , 0.14509804,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34509804, 0.43921569,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.        , 0.00784314, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02745098, 0.46666667, 0.28235294,\n",
       "        0.21960784, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.08235294, 0.09803922,\n",
       "        0.1254902 , 0.08235294, 0.52941176, 0.23529412, 0.        ,\n",
       "        0.54901961, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03529412, 0.15294118,\n",
       "        0.22745098, 0.25490196, 0.31764706, 0.23529412, 0.37254902,\n",
       "        0.17254902, 0.4       , 0.54901961, 0.1254902 , 0.00784314,\n",
       "        0.54117647, 0.09019608, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4       , 0.49411765,\n",
       "        0.25490196, 0.08235294, 0.09803922, 0.09019608, 0.11764706,\n",
       "        0.        , 0.30196078, 0.63137255, 0.        , 0.39215686,\n",
       "        0.58431373, 0.09019608, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.02745098, 0.54901961, 0.41176471,\n",
       "        0.36470588, 0.49411765, 0.51372549, 0.65882353, 0.90588235,\n",
       "        0.67843137, 0.34509804, 0.71372549, 0.46666667, 0.00784314,\n",
       "        0.10980392, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.38431373, 0.51372549,\n",
       "        0.79607843, 0.52941176, 0.1372549 , 0.09803922, 0.        ,\n",
       "        0.52156863, 0.51372549, 0.37254902, 0.37254902, 0.07058824,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24705882, 0.59607843,\n",
       "        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.20784314, 0.23529412, 0.2745098 , 0.39215686,\n",
       "        0.11764706, 0.        , 0.00784314],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09803922, 0.32941176, 0.        ,\n",
       "        0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.1254902 , 0.14509804, 0.09803922, 0.28235294, 0.14509804,\n",
       "        0.50196078, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.29019608, 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.2627451 , 0.08235294, 0.17254902, 0.03529412, 0.        ,\n",
       "        0.2       , 0.36470588, 0.04313725],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.17254902, 0.30980392, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16470588,\n",
       "        0.22745098, 0.16470588, 0.25490196, 0.08235294, 0.        ,\n",
       "        0.        , 0.37254902, 0.2       ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34509804, 0.23529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2627451 ,\n",
       "        0.09803922, 0.10980392, 0.18039216, 0.        , 0.        ,\n",
       "        0.15294118, 0.62352941, 0.04313725],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2627451 ,\n",
       "        0.2745098 , 0.00784314, 0.        , 0.        , 0.17254902,\n",
       "        0.08235294, 0.08235294, 0.2627451 , 0.31764706, 0.34509804,\n",
       "        0.58431373, 0.50196078, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2627451 , 0.43921569, 0.09019608, 0.1254902 , 0.19215686,\n",
       "        0.22745098, 0.18039216, 0.23529412, 0.63921569, 0.41176471,\n",
       "        0.4       , 0.43921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.31764706, 0.2       , 0.10980392, 0.11764706, 0.04313725,\n",
       "        0.04313725, 0.25490196, 0.23529412, 0.34509804, 0.23529412,\n",
       "        0.1372549 , 0.4       , 0.74901961, 0.44705882, 0.70588235,\n",
       "        0.4       , 0.3372549 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29019608,\n",
       "        0.25490196, 0.20784314, 0.19215686, 0.20784314, 0.16470588,\n",
       "        0.17254902, 0.15294118, 0.28235294, 0.29019608, 0.0627451 ,\n",
       "        0.48235294, 0.73333333, 0.0627451 , 0.        , 0.65098039,\n",
       "        0.50196078, 0.19215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34509804,\n",
       "        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02745098, 0.        , 0.35686275, 0.15294118, 0.45490196,\n",
       "        0.71372549, 0.        , 0.        , 0.        , 0.51372549,\n",
       "        0.45490196, 0.14509804, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21960784,\n",
       "        0.77647059, 0.61176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0627451 , 0.2745098 , 0.20784314, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3372549 ,\n",
       "        0.45490196, 0.11764706, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.10980392,\n",
       "        0.24705882, 0.58431373, 0.52156863, 0.01568627, 0.        ,\n",
       "        0.        , 0.46666667, 0.54901961, 0.56862745, 0.02745098,\n",
       "        0.        , 0.01568627, 0.00784314, 0.        , 0.2745098 ,\n",
       "        0.45490196, 0.07058824, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05490196, 0.16470588, 0.18039216, 0.15294118,\n",
       "        0.09019608, 0.08235294, 0.46666667, 0.41176471, 0.        ,\n",
       "        0.23529412, 0.38431373, 0.66666667, 0.04313725, 0.        ,\n",
       "        0.        , 0.00784314, 0.01568627, 0.        , 0.29019608,\n",
       "        0.45490196, 0.05490196, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.39215686, 0.32941176, 0.30196078, 0.72156863, 0.9254902 ,\n",
       "        0.34509804, 0.08235294, 0.11764706, 0.30196078, 0.45490196,\n",
       "        0.24705882, 0.54117647, 0.57647059, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.24705882,\n",
       "        0.41960784, 0.01568627, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.42745098, 0.24705882, 0.01568627, 0.02745098, 0.39215686,\n",
       "        0.21960784, 0.07058824, 0.09803922, 0.1372549 , 0.29019608,\n",
       "        0.44705882, 0.46666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01568627, 0.        , 0.23529412,\n",
       "        0.41176471, 0.00784314, 0.        ],\n",
       "       [0.00784314, 0.08235294, 0.32941176, 0.49411765, 0.09803922,\n",
       "        0.11764706, 0.77647059, 0.09019608, 0.01568627, 0.04313725,\n",
       "        0.09019608, 0.16470588, 0.15294118, 0.10980392, 0.02745098,\n",
       "        0.91372549, 0.08235294, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.24705882,\n",
       "        0.41960784, 0.        , 0.        ],\n",
       "       [0.44705882, 0.54117647, 0.2745098 , 0.19215686, 0.15294118,\n",
       "        0.09019608, 0.84313725, 0.2745098 , 0.05490196, 0.10980392,\n",
       "        0.1372549 , 0.20784314, 0.23529412, 0.0627451 , 0.66666667,\n",
       "        0.37254902, 0.        , 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.28235294,\n",
       "        0.45490196, 0.00784314, 0.        ],\n",
       "       [0.05490196, 0.56862745, 0.73333333, 0.69411765, 0.54117647,\n",
       "        0.10980392, 0.45490196, 0.74117647, 0.09019608, 0.11764706,\n",
       "        0.19215686, 0.15294118, 0.05490196, 0.31764706, 0.79607843,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.11764706,\n",
       "        0.31764706, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.09019608, 0.54901961, 0.76078431,\n",
       "        0.73333333, 0.55686275, 0.85882353, 0.67843137, 0.54901961,\n",
       "        0.46666667, 0.41176471, 0.4745098 , 0.70588235, 0.02745098,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01568627, 0.        , 0.37254902,\n",
       "        1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1254902 , 0.09803922, 0.31764706, 0.30196078,\n",
       "        0.4       , 0.41176471, 0.36470588, 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.21960784,\n",
       "        0.68627451, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 0, ..., 6, 6, 1], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для того, чтобы учить через cross_entropy нам нужно сделать OHE таргетам. И эта функция есть в keras!\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "y_val_ohe = to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 2s 34us/sample - loss: 1.8986 - categorical_accuracy: 0.4763 - val_loss: 1.4738 - val_categorical_accuracy: 0.6307\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 1s 14us/sample - loss: 1.2020 - categorical_accuracy: 0.6655 - val_loss: 1.0251 - val_categorical_accuracy: 0.6802\n"
     ]
    }
   ],
   "source": [
    "## Первая простая нейронка\n",
    "\n",
    "tf.random.set_seed(42) # фиксируем random_seed\n",
    "\n",
    "model = Sequential(name = 'first_try')\n",
    "model.add(L.Input(shape = (28,28))) # входной нейрон с данными. Его обычно можно опускать, сразу передавая \n",
    "# в нейрон размерность. Но Dense ячейки не умеют работать с картинками, поэтому оставляем Input\n",
    "model.add(L.Flatten()) # разворачиваем картинку в вектор\n",
    "model.add(L.Dense(100,  kernel_initializer='random_normal',name='First')) # можно именовать и потом брать слои по именам\n",
    "model.add(L.ReLU()) # добавляем активацию\n",
    "model.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output'))\n",
    "model.add(L.Softmax())\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4) # так же нам нужно указать оптимайзер\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) # и собрать нашу модель, указав метрики,loss и оптимизатор\n",
    "\n",
    "\n",
    "history1 = model.fit(X_train,y_train_ohe,batch_size=500,epochs=2,validation_data = (X_val,y_val_ohe))\n",
    "# и процесс обучения. Задаем количество эпох, размер батча и валидационную часть наших данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 500,\n",
       " 'epochs': 2,\n",
       " 'steps': 100,\n",
       " 'samples': 50000,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss',\n",
       "  'categorical_accuracy',\n",
       "  'val_loss',\n",
       "  'val_categorical_accuracy']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.8986167120933533, 1.2020430505275725],\n",
       " 'categorical_accuracy': [0.47632, 0.66554],\n",
       " 'val_loss': [1.4737698197364808, 1.025083103775978],\n",
       " 'val_categorical_accuracy': [0.6307, 0.6802]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 1s 15us/sample - loss: 1.8141 - categorical_accuracy: 0.4979 - val_loss: 1.3973 - val_categorical_accuracy: 0.6449\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 1.1440 - categorical_accuracy: 0.6720 - val_loss: 0.9782 - val_categorical_accuracy: 0.6839\n"
     ]
    }
   ],
   "source": [
    "# Эту же модель можно записать чуть в меньшее количество строчек кода\n",
    "model = Sequential(name = 'first_try')\n",
    "model.add(L.Input(shape = (28,28))) \n",
    "model.add(L.Flatten()) \n",
    "model.add(L.Dense(100,  kernel_initializer='random_normal',name='First',activation='relu')) # можно именовать и потом брать слои по именам\n",
    "model.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output',activation='softmax'))\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4) \n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) \n",
    "\n",
    "history1 = model.fit(X_train,y_train_ohe,batch_size=500,epochs=2,validation_data = (X_val,y_val_ohe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "?L.Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из приятного - все в таком подходе можно кастомизировать под себя!\n",
    "Но пока продолжим рассмотрение о следующем подходе сборки моделей.\n",
    "Класс Sequential не дает нам вообще никакой гибкости, позволяя набирать слои только последовательно.\n",
    "Что же у нас есть новый герой  - Model.\n",
    "Он позволяет собирать сетки практически любой архитектуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model  # подгружаем нужные модули. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 'uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28)) # задаем вход\n",
    "x = L.Flatten()(input_tensor)# применение нейрона к входу\n",
    "x = L.Dense(100, kernel_initializer=init, activation=act)(x) # повторяем всю логику сколько нам надо раз\n",
    "x = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "output_tensor = L.Dense(10, kernel_initializer=init, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(input_tensor, output_tensor) # Keras под капотом сам собирает граф.\n",
    "# Если он может получить из входа выхода то вы великолепны.\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 'uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28)) # задаем вход\n",
    "x = L.Flatten()(input_tensor)# применение нейрона к входу\n",
    "\n",
    "# input_tensor_2 = L.Input(shape=(28, 28)) # задаем вход\n",
    "# x_2 = L.Flatten()(input_tensor_2)# применение нейрона к входу\n",
    "\n",
    "x = L.Dense(100, kernel_initializer=init, activation=act)(x) # повторяем всю логику сколько нам надо раз\n",
    "x = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "# y = L.Dense(10, kernel_initializer=init, activation='softmax')(x_2)\n",
    "output_tensor = L.Dense(10, kernel_initializer=init, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(input_tensor, output_tensor) # Keras под капотом сам собирает граф.\n",
    "# Если он может получить из входа выхода то вы великолепны.\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 1s 20us/sample - loss: 1.6832 - categorical_accuracy: 0.5463 - val_loss: 1.0566 - val_categorical_accuracy: 0.6478\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 1s 13us/sample - loss: 0.8848 - categorical_accuracy: 0.6717 - val_loss: 0.8044 - val_categorical_accuracy: 0.6806\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train_ohe,batch_size=500,epochs=2,validation_data = (X_val,y_val_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой подход позволяет делать практически любой гибкости нейронки. Как пример - двухголовая!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_2 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 784)          0           Input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 784)          0           Input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 100)          78500       flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 100)          78500       flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 100)          10100       dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 100)          10100       dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 200)          0           dense_37[0][0]                   \n",
      "                                                                 dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 10)           2010        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 179,210\n",
      "Trainable params: 179,210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1 = L.Input(shape=(28, 28),name='Input_1')\n",
    "input_2 = L.Input(shape=(28, 28),name='Input_2')\n",
    "\n",
    "x1 = L.Flatten()(input_1)\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x1)\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x1)\n",
    "\n",
    "x2 = L.Flatten()(input_2)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x2)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x2)\n",
    "\n",
    "x = L.concatenate([x1, x2]) # Волшебное слово, которое позволяет нам соеденять несколько потоков наших данных\n",
    "output = L.Dense(10, kernel_initializer=init, activation='softmax',name='out')(x)\n",
    "\n",
    "model = keras.Model([input_1, input_2], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 1s 22us/sample - loss: 1.3714 - categorical_accuracy: 0.6164 - val_loss: 0.8260 - val_categorical_accuracy: 0.6711\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 1s 14us/sample - loss: 0.7213 - categorical_accuracy: 0.7305 - val_loss: 0.6702 - val_categorical_accuracy: 0.7558\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train,X_train],y_train_ohe,batch_size=500,epochs=2,validation_data = ([X_val,X_val],y_val_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit({'Input_1':X_train,'Input_2':X_train,'out':y_train_ohe},batch_size=500,epochs=2,validation_data = ([X_val,X_val],y_val_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужно для винды, если не видит путь до graphviz\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model) # можно нарисовать модельку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Несколько выходов и функций потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 784)          0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 100)          78500       flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 100)          78500       flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 100)          78500       flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            101         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1010        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            101         dense_42[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 236,712\n",
      "Trainable params: 236,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "init = 'uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28))\n",
    "\n",
    "x = L.Flatten()(input_tensor)\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "x3 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "\n",
    "output_1 = L.Dense(1, kernel_initializer=init, activation='sigmoid',name='gender')(x1)\n",
    "output_2 = L.Dense(10, kernel_initializer=init, activation='softmax',name='income')(x2)\n",
    "output_3 = L.Dense(1, kernel_initializer=init,name='age')(x3)\n",
    "\n",
    "model = keras.Model(input_tensor, [output_1, output_2, output_3])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы модель не переобучилась под самую большую функцию потерь\n",
    "# их можно взвесить\n",
    "model.compile(optimizer='adam', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "                                    loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "\n",
    "# если дали выходам имена, можно вот так: \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "                    \n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помните статью про то, как люди рисовали функции потерь? [Теперь появилась галерея!](https://losslandscape.com/gallery/) Есть подход как skip-connection, он сильно меняет нашу функцию.\n",
    "\n",
    "![](https://i.stack.imgur.com/UDvbg.png)\n",
    "\n",
    "Такую модель нельзя собрать через `Sequence`-стиль, но можно через функциональный стиль. Давайте попробуем сделать это. Заодно посмотрим насколько сильно в нашей ситуации будет меняться траектория обучения. (Сравним обычный 6-ти слойный персептрон и с прокидыванием инфы, например со 2 слоя на 5ый). Ну и также сразу поэксперементируем с функциями активаций и batchnorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMETASK\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ  создайте сеть по инструкциям ниже\n",
    "tf.random.set_seed(42)\n",
    "## Соберите обычный 6ти слойный перспептрон\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMETASK\n",
    "## Соберите обычный 6ти слойный перспептрон с функциями активации сигмоид\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMETASK\n",
    "## Соберите с батчнормом и релу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 784)          0           input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 100)          78500       flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 100)          10100       dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 100)          10100       dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 100)          10100       dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 200)          0           dense_63[0][0]                   \n",
      "                                                                 dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 100)          20100       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1010        dense_64[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 129,910\n",
      "Trainable params: 129,910\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# HOMETASK\n",
    "## Соберите ну и наконец прокидывание данных\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для удобной отрисовки всего\n",
    "\n",
    "def plot_history(histories, key='loss', start=0):\n",
    "    plt.figure(figsize=(16,10))\n",
    "\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch[start:], history.history['val_'+key][start:],\n",
    "                       #'--', \n",
    "                       label=name.title()+' Val')\n",
    "            #plt.plot(history.epoch[start:], history.history[key][start:], color=val[0].get_color(),\n",
    "            #     label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([start, max(history.epoch)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('simple',    history_simple), \n",
    "              ('simple_sigmoid', history_simple_sigmoid),\n",
    "              ('simple_BN_and_init', history_simple_BN_and_init),\n",
    "              ('complex!!!',   history_complex)\n",
    "             ],\n",
    "             start=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Более интересная часть - кастомизация\n",
    "В keras уже есть несколько удобных callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.callbacks.ModelCheckpoint"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EarlyStopping # останавливает обучение если наша метрика не меняет n эпох\n",
    "LearningRateScheduler # меняет наш learning_rate по расписанию\n",
    "ReduceLROnPlateau # понижает на LR если не происходит улучшения\n",
    "ModelCheckpoint # сохраняет нашу лучшую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=3)\n",
    "reduce_on_plateau = ReduceLROnPlateau(patience=3)\n",
    "# filepath=\"checkpoint_path/weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"checkpoint_path/weights-improvement.hdf5\"\n",
    "model_checkpoing = ModelCheckpoint(filepath,\n",
    "                                   save_best_only=True,\n",
    "                                  save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model():\n",
    "    model = Sequential(name = 'simple_model')\n",
    "    model.add(L.Input(shape = (28,28))) \n",
    "    model.add(L.Flatten()) \n",
    "    model.add(L.Dense(100,  kernel_initializer='random_normal',name='First',activation='relu'))\n",
    "    model.add(L.Dense(100,  kernel_initializer='random_normal',name='Second',activation='relu'))\n",
    "    model.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output',activation='softmax'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4) \n",
    "    model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "                 metrics=[\"categorical_accuracy\"]) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = create_simple_model()\n",
    "\n",
    "history = model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau,model_checkpoing],verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('checkpoint_path/weights-improvement.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath=\"checkpoint_path/full_model_improvement.hdf5\"\n",
    "model_checkpoing = ModelCheckpoint(filepath,\n",
    "                                   save_best_only=True,\n",
    "                                  save_weights_only=False)\n",
    "simple_model = create_simple_model()\n",
    "\n",
    "history = simple_model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau,model_checkpoing],verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.4370 - categorical_accuracy: 0.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43701135449409484, 0.8472]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.evaluate(x=X_val,y=y_val_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Способ писать свои собственные callbacks\n",
    "from tensorflow.keras import callbacks\n",
    " \n",
    "class My_Callback(callbacks.Callback):     # Класс My_Callback унаследовал свойства класса Callback\n",
    "    def on_train_begin(self, logs={}):           # Функция, которая выполняется в начале обучения \n",
    "        return\n",
    " \n",
    "    def on_train_end(self, logs={}):             # Функция, которая выполняется в конце обучения \n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, logs={}):           # В начале каждой эпохи \n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        # В конце каждой эпохи\n",
    "        return\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):    # В начале батча\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):      # В конце батча \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "class Printlogs(callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==10:\n",
    "            print(logs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = create_simple_model()\n",
    "our_callback = Printlogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4832637459039688, 'categorical_accuracy': 0.83334, 'val_loss': 0.4912553161382675, 'val_categorical_accuracy': 0.8295}\n"
     ]
    }
   ],
   "source": [
    "history = simple_model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [our_callback],\n",
    "                           verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000149011612\n",
      "0.05000000074505806\n",
      "0.02500000037252903\n",
      "0.012500000186264515\n",
      "0.0062500000931322575\n",
      "0.0031250000465661287\n",
      "0.0015625000232830644\n",
      "0.0007812500116415322\n",
      "0.0003906250058207661\n",
      "0.00019531250291038305\n",
      "9.765625145519152e-05\n",
      "4.882812572759576e-05\n",
      "2.441406286379788e-05\n",
      "1.220703143189894e-05\n",
      "6.10351571594947e-06\n",
      "3.051757857974735e-06\n",
      "1.5258789289873675e-06\n",
      "7.629394644936838e-07\n",
      "3.814697322468419e-07\n",
      "1.9073486612342094e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Напишем изменение скорости обучения\n",
    "INIT_LR=0.1\n",
    "# Стратегия для понижения скорости\n",
    "def lr_scheduler(epoch):\n",
    "    drop = 0.5\n",
    "    epochs_drop = 1.0\n",
    "    lrate = INIT_LR * np.math.pow(drop, np.math.floor((epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(lr_scheduler)\n",
    "# класс чтобы отслеживать бесчинства\n",
    "class Print_lr(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(float(tf.keras.backend.get_value(self.model.optimizer.lr)))\n",
    "        # чтобы установить свой LR надо указать\n",
    "        # LR_OUR = ....\n",
    "        # tf.keras.backend.set_value(self.model.optimizer.lr, LR_OUR)\n",
    "\n",
    "\n",
    "simple_model = create_simple_model()\n",
    "history = simple_model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [lrate,Print_lr()],\n",
    "                           verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMETASK\n",
    "# Давайте заставим модель посчитать метрики каждую эпоху, как пример\n",
    "# Считать будем на X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кастомные loss и метрики\n",
    "Что уже есть\n",
    "https://keras.io/api/metrics/\n",
    "\n",
    "https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)\n",
    "fahrenheit = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7 samples\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 0s 30ms/sample - loss: 3164.0806\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 3161.7905\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 0s/sample - loss: 3159.5017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20b89ebac88>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam( )\n",
    "\n",
    "model.compile(loss='mse', optimizer=opt)\n",
    "model.fit(celsius, fahrenheit,  epochs=3, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7 samples\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 0s 31ms/sample - loss: 3712.9524\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 3710.3984\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 285us/sample - loss: 3707.8442\n",
      "Wall time: 268 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20b8b6e9e88>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam( )\n",
    "\n",
    "model.compile(loss=custom_loss_function, optimizer=opt)\n",
    "model.fit(celsius, fahrenheit,  epochs=3,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## тоже самое можно делать и с метриками. Также можно следить сразу за несколькими метриками, что бывает полезно.\n",
    "## Если хотим добавить совсем сложную логику то мы это будем делать через callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке немного поработаем с градусами по цельсию и фаренгейту! Снова попробуем восстановить формулу \n",
    "\n",
    "$$ f = c \\times 1.8 + 32 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20b8b981048>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## возьмем срезы\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "model = Sequential()\n",
    "model.add(L.Dense(1,name='our_neural'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(0.1 )\n",
    "\n",
    "model.compile(loss='mse', optimizer=opt)\n",
    "model.fit(celsius, fahrenheit,  epochs=600, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential_3/our_neural/kernel:0' shape=(1, 1) dtype=float64, numpy=array([[1.80835704]])>,\n",
       " <tf.Variable 'sequential_3/our_neural/bias:0' shape=(1,) dtype=float64, numpy=array([30.72060637])>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## элементарная задача, но из-за того, что данные не скалированы сходились вечность\n",
    "our_layer = model.get_layer(name='our_neural')\n",
    "our_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
       "array([[-41.61367519],\n",
       "       [ 12.63703598],\n",
       "       [ 30.72060637],\n",
       "       [ 45.18746269],\n",
       "       [ 57.84596196],\n",
       "       [ 70.50446124],\n",
       "       [ 99.43817387]])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_layer(np.array(celsius).reshape((7,1))) ## Берем прогнозы от слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### HOMETASK\n",
    " Есть понимание, как взять определить в callback на какой эпохе мы получили правильное значение весов? Проверить как ведет себя наша нейронка? (с учетом того, что мы точно знаем формулу)\n",
    " Ну и заодно быстро проверить гипотезу - а поможет ли нам batchnorm в данной ситуации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем класс нейронки с TF и keras вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# транспонировали выборку\n",
    "x_train = celsius[:,None]\n",
    "y_train = fahrenheit[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "class Super_puper_neural_net(keras.Model):\n",
    "    \n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(Super_puper_neural_net, self).__init__()\n",
    "        self.fc1 = L.Dense(n_hidden_neurons, kernel_initializer='glorot_uniform',\n",
    "                           activation='relu', trainable=True)\n",
    "        self.fc2 = L.Dense(n_hidden_neurons, kernel_initializer='glorot_uniform',\n",
    "                           trainable=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
       "array([[ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [11.9940236 ],\n",
       "       [22.48879425],\n",
       "       [32.98356491],\n",
       "       [56.97161211]])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_super = Super_puper_neural_net(1)\n",
    "model_super.encode(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошибка для модели\n",
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_mean((y_pred-y_true)**2)\n",
    "\n",
    "# оптимизатор \n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "# процесс оптимизации\n",
    "def model_train(X, Y):\n",
    "\n",
    "    # находим loss и пробрасываем градиент\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = model_super.encode(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "\n",
    "    # Вычисляем градиенты\n",
    "    gradients = g.gradient(loss, model_super.variables)\n",
    "    \n",
    "    # Обновляем веса a и b в ходе одной итерации спуска \n",
    "    optimizer.apply_gradients(zip(gradients, model_super.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 3012.841216\n",
      "step: 100, loss: 2465.832894\n",
      "step: 200, loss: 1918.373436\n",
      "step: 300, loss: 1520.655473\n",
      "step: 400, loss: 1231.907075\n",
      "step: 500, loss: 1021.899716\n",
      "step: 600, loss: 868.605334\n",
      "step: 700, loss: 756.273940\n",
      "step: 800, loss: 673.691818\n",
      "step: 900, loss: 612.798067\n"
     ]
    }
   ],
   "source": [
    "#Обучение\n",
    "epochs = 1000 # число эпох \n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Делаем щаг градиентного спуска \n",
    "    model_train(x_train, y_train)\n",
    "    \n",
    "    # Каждую сотую итерацию следим за тем, что произошло\n",
    "    if i%100 == 0:\n",
    "        y_pred = model_super.encode(x_train)\n",
    "        loss_val = mean_square(y_pred, y_train)\n",
    "        print(\"step: %i, loss: %f\" % (i, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Свой слой на Tensorflow для Keras\n",
    "\n",
    "Новые слои можно писать на основе керасовского класса `Layer`. Если прописать `help(tf.keras.layers.Layer)`, можно почитать про него. Если в кратце, нужно реализовать три части: \n",
    "\n",
    "* Конструктор, в нём мы описываем гиперпараметры \n",
    "* Метод `build`, в которм мы описываем все переменные \n",
    "* Метод `call`, который делает forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(L.Layer):\n",
    "    \n",
    "    # Задаём консруктор \n",
    "    def __init__(self, units=32):\n",
    "        super(MyLinear, self).__init__()  # чтобы коректно унаследовались методы\n",
    "        self.units = units                # число нейронов\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # add_weight внутри build то же самое что и Variable, но совместимо с Keras\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal', \n",
    "                                 trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal', \n",
    "                                 trainable=True)\n",
    "\n",
    "    # Применение \n",
    "    def call(self, inputs):\n",
    "        # сразу делаем и линейное преобразование и ReLU (а почему бы и нет)\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom = Sequential(name = 'simple_model')\n",
    "model_custom.add(L.Input(shape = (28,28))) \n",
    "model_custom.add(L.Flatten()) \n",
    "model_custom.add(L.Dense(100,  kernel_initializer='random_normal',name='First',activation='relu'))\n",
    "model_custom.add(MyLinear()) ### Самый красивый слой\n",
    "model_custom.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output',activation='softmax'))\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4) \n",
    "model_custom.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 1s 25us/sample - loss: 2.1417 - categorical_accuracy: 0.3675 - val_loss: 1.9107 - val_categorical_accuracy: 0.5202\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 1.6032 - categorical_accuracy: 0.5473 - val_loss: 1.3239 - val_categorical_accuracy: 0.5681\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 1s 16us/sample - loss: 1.1260 - categorical_accuracy: 0.6175 - val_loss: 0.9910 - val_categorical_accuracy: 0.6533\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 0.8973 - categorical_accuracy: 0.6785 - val_loss: 0.8449 - val_categorical_accuracy: 0.6941\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 1s 19us/sample - loss: 0.7869 - categorical_accuracy: 0.7180 - val_loss: 0.7632 - val_categorical_accuracy: 0.7224\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 1s 18us/sample - loss: 0.7190 - categorical_accuracy: 0.7432 - val_loss: 0.7116 - val_categorical_accuracy: 0.7398\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 0.6720 - categorical_accuracy: 0.7599 - val_loss: 0.6715 - val_categorical_accuracy: 0.7618\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 1s 18us/sample - loss: 0.6369 - categorical_accuracy: 0.7742 - val_loss: 0.6407 - val_categorical_accuracy: 0.7714\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 1s 18us/sample - loss: 0.6094 - categorical_accuracy: 0.7838 - val_loss: 0.6167 - val_categorical_accuracy: 0.7804\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 1s 19us/sample - loss: 0.5869 - categorical_accuracy: 0.7916 - val_loss: 0.5963 - val_categorical_accuracy: 0.7842\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 0.5689 - categorical_accuracy: 0.7993 - val_loss: 0.5800 - val_categorical_accuracy: 0.7946\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 1s 18us/sample - loss: 0.5529 - categorical_accuracy: 0.8054 - val_loss: 0.5646 - val_categorical_accuracy: 0.8025\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 0.5392 - categorical_accuracy: 0.8116 - val_loss: 0.5524 - val_categorical_accuracy: 0.8058\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 1s 21us/sample - loss: 0.5279 - categorical_accuracy: 0.8162 - val_loss: 0.5435 - val_categorical_accuracy: 0.8101\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 1s 19us/sample - loss: 0.5167 - categorical_accuracy: 0.8205 - val_loss: 0.5307 - val_categorical_accuracy: 0.8154\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 0.5070 - categorical_accuracy: 0.8239 - val_loss: 0.5218 - val_categorical_accuracy: 0.8205\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 0.4985 - categorical_accuracy: 0.8271 - val_loss: 0.5143 - val_categorical_accuracy: 0.8225\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 1s 16us/sample - loss: 0.4902 - categorical_accuracy: 0.8304 - val_loss: 0.5058 - val_categorical_accuracy: 0.8262\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 1s 16us/sample - loss: 0.4830 - categorical_accuracy: 0.8331 - val_loss: 0.4990 - val_categorical_accuracy: 0.8250\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 1s 15us/sample - loss: 0.4768 - categorical_accuracy: 0.8357 - val_loss: 0.4923 - val_categorical_accuracy: 0.8295\n"
     ]
    }
   ],
   "source": [
    "history = model_custom.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и нам остался пример, как взять срез модели. Посмотреть прогнозы в середине"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_simple_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_23 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "First (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "Second (Dense)               (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau],verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем выходы верхних 2х слоев\n",
    "layer_outputs = [layer.output for layer in model.layers[1:3]]\n",
    "# создаем модель, которая вернет эти выходы с учетом заданнаго входа\n",
    "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = activation_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'First_8/Identity:0' shape=(None, 100) dtype=float64>,\n",
       " <tf.Tensor 'Second_6/Identity:0' shape=(None, 100) dtype=float64>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Что сегодня не вошло - как переопределить градиенты для своих слоев (на уровне keras очень геморойно, если уже занимаетесь этим то вряд ли пишете на верхнеуровневом фраемворке)\n",
    "Как работать с уже готовыми и обучеными моделями, дофичивать нейронки по кусочкам. Но это уже в следующих сериях :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
