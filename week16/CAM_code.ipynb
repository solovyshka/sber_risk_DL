{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install torchvision\n",
    "\n",
    "pip install opencv-python\n",
    "\n",
    "# Mac OS \n",
    "conda install -c conda-forge opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from week16.CAM_vis import CAM_localization\n",
    "from week16.imagenet_class_map import imagenet_classmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем модлеь ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "# Достаем обучающие параметры\n",
    "params = list(resnet.parameters())\n",
    "# и потом берем только веса последнего полносвязного слоя\n",
    "weights_softmax = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "# Forward модели\n",
    "res50_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Пишем callback, который сработает,\n",
    "# когда хотим достать выход после нужного слоя\n",
    "last_convs = []\n",
    "def hook(module, input, output):\n",
    "    last_convs.append(output)\n",
    "        \n",
    "res50_model.layer4[2].conv3.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward(batch_t):\n",
    "    res50_model = models.resnet50(pretrained=True)\n",
    "    params = list(res50_model.parameters())\n",
    "    weights_softmax = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "    last_convs = []\n",
    "    def hook(module, input, output):\n",
    "        last_convs.append(output)\n",
    "\n",
    "    res50_model = models.resnet50(pretrained=True)\n",
    "    res50_model.layer4[2].conv3.register_forward_hook(hook)\n",
    "\n",
    "    out = res50_model(batch_t)\n",
    "    class_idx = np.argmax(out[0].detach().numpy())\n",
    "    print(class_idx, imagenet_classmap[class_idx])\n",
    "\n",
    "    return class_idx, last_convs, weights_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализуем опреацию вычисления Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classmap(class_idx, last_convs, weight_softmax):\n",
    "    h = w = 7\n",
    "    nc = 2048\n",
    "    reshape_convs = torch.squeeze(last_convs[0], 0).reshape((nc, h * w)).detach().numpy()\n",
    "    classmap = weight_softmax[class_idx].dot(reshape_convs)\n",
    "    classmap = np.reshape(classmap, [h, w])\n",
    "\n",
    "    return classmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как подать в CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    img = Image.open(path)\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основная логика получения CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_CAM(path):    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    img = Image.open(path)\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "    class_idx, last_convs, weights_softmax = model_forward(batch_t)\n",
    "\n",
    "    classmap = get_classmap(class_idx, last_convs, weights_softmax)\n",
    "\n",
    "    img2 = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cam = CAM_localization()\n",
    "    cam.get_localization_map(img2, classmap)\n",
    "\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
