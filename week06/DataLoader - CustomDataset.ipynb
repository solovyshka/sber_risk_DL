{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DataLoader__ -- класс в PyTorch, который позволяет итеративно проходить по датасету, отвечает за оркестрацию всего процесса работы с датасетом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DataLoaderParams.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __dataset__ -- позволяет создать кастомные классы для работы с датасетом, где можно указать логику формирвоания батча.\n",
    "- __sampler__ -- определяет порядок элементов из датасета, которые будут идти в батч, то есть это список индексов, объединенных в батч. Удобно переопределять, когда обучение распредленное.  \n",
    "- __collate_fn__ -- позволяет сделать финальную предобработку над батчем данных. Если, например, в батч попали последовательности разных размеров, то после уже сбора батча, можно будет дополнить последовательности нулями относительно максимально длиной последовательности.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    # Конструктор, где считаем датасет\n",
    "    def __init__(self, dataset_path):\n",
    "        with open(dataset_path, 'rb') as f:\n",
    "            self.X, self.target = pickle.load(f)\n",
    "\n",
    "        return\n",
    "    \n",
    "    # Переопределяем метод вычисление размера датасета\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # Переопределяем метод,\n",
    "    # который достает по индексу наблюдение из датасет\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.target[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSampler(Sampler):\n",
    "\n",
    "    # Конструктор, где инициализируем индексы элементов\n",
    "    def __init__(self, data):\n",
    "        self.data_indices = np.arange(len(data))\n",
    "\n",
    "        shuffled_indices = np.random.permutation(len(self.data_indices))\n",
    "\n",
    "        self.data_indices = np.ascontiguousarray(self.data_indices)[shuffled_indices]\n",
    "\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_indices)\n",
    "\n",
    "    # Возращает итератор,\n",
    "    # который будет возвращать индексы из перемешанного датасета\n",
    "    def __iter__(self):\n",
    "        return iter(self.data_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_dataset, train_sampler,\n",
    "                       test_dataset, test_sampler):\n",
    "    train_loader = DataLoader(dataset=train_dataset, sampler=train_sampler,\n",
    "                              batch_size=BATCH_SIZE, collate_fn=collate,\n",
    "                              shuffle=False)\n",
    "\n",
    "    test_loader = DataLoader(dataset=test_dataset, sampler=test_sampler,\n",
    "                             batch_size=BATCH_SIZE, collate_fn=collate,\n",
    "                             shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем объекты Custom Dataset и Sampler\n",
    "train_ds = CustomDataset('./data/X_train_cat.pickle')\n",
    "train_sampler = CustomSampler(train_ds.X)\n",
    "\n",
    "test_ds = CustomDataset('./data/X_test_cat.pickle')\n",
    "test_sampler = CustomSampler(test_ds.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loader(train_ds, train_sampler,\n",
    "                                               test_ds, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    print('Run train')\n",
    "    for epoch in range(EPOCHS):\n",
    "        for features, labels in train_loader:\n",
    "            print(features, labels)\n",
    "\n",
    "        # Run validation\n",
    "        print('Run validation')\n",
    "        for features, labels in test_loader:\n",
    "            print(features, labels)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
